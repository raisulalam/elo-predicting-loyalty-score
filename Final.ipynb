{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import gc\n",
    "gc.collect()\n",
    "import os\n",
    "from six.moves import urllib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy.stats import norm, skew\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys\n",
    "import joblib\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error\n",
    "\n",
    "\n",
    "from sklearn import metrics #accuracy measure\n",
    "from sklearn.metrics import confusion_matrix #for confusion matrix\n",
    "from scipy.stats import reciprocal, uniform\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedKFold\n",
    "from sklearn.model_selection import KFold #for K-fold cross validation\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from scipy import sparse\n",
    "import pickle\n",
    "import re\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm as lgbm\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "from sklearn.linear_model import BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function returns all the features for a given customer which already exists\n",
    "\n",
    "\"\"\"\n",
    "def existing_cust_feature(param):    \n",
    "    ids=param['card_id']\n",
    "    data = [{'first_active_month': param['first_active_month'],'card_id':param['card_id'],'feature_1':param['feature_1'],'feature_2':param['feature_2'],'feature_3':param['feature_3']}]\n",
    "    df = pd.DataFrame(data)\n",
    "    details=pd.read_pickle('../input/todaydata/train.pkl')\n",
    "    exists = details.isin([ids]).any().any()\n",
    "    if (exists):\n",
    "        print(\"The customer is an existing customer\")\n",
    "    else:\n",
    "        print(\"The customer is new, please go for new customer option\")\n",
    "        sys.exit()\n",
    "    \n",
    "    cust_data=details.loc[details['card_id'] == param['card_id']]\n",
    "    \n",
    "    order_label_1 = pd.read_pickle('../input/data-prod/feature_1')\n",
    "    order_label_2 = pd.read_pickle('../input/data-prod/feature_2')\n",
    "    order_label_3 = pd.read_pickle('../input/data-prod/feature_3')\n",
    "    \n",
    "    for features in ['feature_1','feature_2','feature_3']:\n",
    "        if(features=='feature_1'):\n",
    "            df[features] = df[features].map(order_label_1)\n",
    "        if(features=='feature_2'):\n",
    "            df[features] = df[features].map(order_label_2)\n",
    "        if(features=='feature_3'):\n",
    "            df[features] = df[features].map(order_label_3)\n",
    "        \n",
    "    df['first_active_month']=pd.to_datetime(df['first_active_month'],format='%Y-%m')\n",
    "    df['day'] = (datetime.date(2018, 2, 1) - df['first_active_month'].dt.date).dt.days\n",
    "    df['quarter'] = df['first_active_month'].dt.quarter\n",
    "\n",
    "    for feature in ['feature_1','feature_2','feature_3']:\n",
    "        column=feature+'_day'\n",
    "        df[column] = df['day'] * df[feature]\n",
    "        column=feature+'_day_ratio'\n",
    "        df[column] = df[feature] / df['day']\n",
    "    \n",
    "    for feature in ['first_active_month', 'card_id', 'feature_1', 'feature_2', 'feature_3', 'day', 'quarter', 'feature_1_day','feature_1_day_ratio', 'feature_2_day', 'feature_2_day_ratio','feature_3_day', 'feature_3_day_ratio']:\n",
    "        cust_data[feature]=df[feature]\n",
    "    \n",
    "    with open(\"../input/feature/feature.txt\", \"rb\") as fp:\n",
    "        features = pickle.load(fp)\n",
    "    feature = [c for c in cust_data.columns if c not in ['first_active_month', 'target', 'card_id', 'outliers',\n",
    "                  'hist_purchase_date_max', 'hist_purchase_date_min', 'hist_card_id_size',\n",
    "                  'new_purchase_date_max', 'new_purchase_date_min', 'new_card_id_size']] \n",
    "\n",
    "    return cust_data[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This function predicts the loyalty score for an existing customer\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def loyalty_score_prediction_1(param):\n",
    "    all_features=existing_cust_feature(param)\n",
    "    predictions_1 = np.zeros(len(all_features))\n",
    "    \n",
    "    lgbm_1 = joblib.load('../input/finalmodel/lgb_model-1.pkl')\n",
    "    predictions_1 += lgbm_1.predict(all_features) / 5\n",
    "    \n",
    "    lgbm_2 = joblib.load('../input/finalmodel/lgb_model-2.pkl')\n",
    "    predictions_2 = np.zeros(len(all_features))\n",
    "    predictions_2 += lgbm_2.predict(all_features) / (5*2)\n",
    "    \n",
    "    final_model = joblib.load('../input/finalmodel/lgb_model-3.pkl')\n",
    "    predictions_3 = np.zeros(len(all_features))\n",
    "    test_stack = np.vstack([predictions_1, predictions_2]).transpose()\n",
    "    predictions_3 += final_model.predict(test_stack) / 5\n",
    "    \n",
    "    return predictions_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This function returns the loyalty score as well as RMSE for an existing customer\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def loyalty_score_prediction_2(param,target):\n",
    "    all_features=existing_cust_feature(param)\n",
    "    predictions_1 = np.zeros(len(all_features))\n",
    "    \n",
    "    lgbm_1 = joblib.load('../input/finalmodel/lgb_model-1.pkl')\n",
    "    predictions_1 += lgbm_1.predict(all_features) / 5\n",
    "    \n",
    "    lgbm_2 = joblib.load('../input/finalmodel/lgb_model-2.pkl')\n",
    "    predictions_2 = np.zeros(len(all_features))\n",
    "    predictions_2 += lgbm_2.predict(all_features) / (5*2)\n",
    "    \n",
    "    final_model = joblib.load('../input/finalmodel/lgb_model-3.pkl')\n",
    "    predictions_3 = np.zeros(len(all_features))\n",
    "    test_stack = np.vstack([predictions_1, predictions_2]).transpose()\n",
    "    predictions_3 += final_model.predict(test_stack) / 5\n",
    "    \n",
    "    rmse=root_mean_squared_error(target,predictions_3)\n",
    "    \n",
    "    return predictions_3,rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    \"\"\"Root mean squared error regression loss\"\"\"\n",
    "    return np.sqrt(np.mean(np.square(y_true-y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_features(data):\n",
    "  import datetime \n",
    "  current_time = datetime.datetime.now()\n",
    "  data['months_diff']= (current_time.year - data.purchase_date.dt.year) * 12 + (current_time.month - data.purchase_date.dt.month)\n",
    "  data['months_diff'] = data['months_diff'] + data['month_lag']\n",
    "  data['purchase_month']=data.purchase_date.dt.month\n",
    "  data['purchase_day']=data['purchase_date'].dt.day\n",
    "  data['weekday']=data['purchase_date'].dt.weekday\n",
    "  data['purchase_year'] = data['purchase_date'].dt.year\n",
    "  data['weekofyear'] = data['purchase_date'].dt.weekofyear\n",
    "  data['dayofweek'] = data['purchase_date'].dt.dayofweek\n",
    "  data['weekend'] = (data.purchase_date.dt.weekday >=5).astype(int)\n",
    "  data['hour'] = data['purchase_date'].dt.hour\n",
    "\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_func(data,str_data):\n",
    "    agg_func= {\n",
    "      'authorized_flag':['sum','mean'],\n",
    "      'card_id':['size','count'],\n",
    "      'category_1':['mean','sum','max','min'],\n",
    "      'installments':['max','var','mean','skew','sum'],\n",
    "      'merchant_category_id':['nunique'],\n",
    "      'month_lag':['max','mean','min','var','skew'],\n",
    "      'purchase_amount':['max','mean','min','var','sum','skew'],\n",
    "      'subsector_id':['nunique'],\n",
    "      'months_diff':['mean','max','min','var','skew'],\n",
    "      'purchase_month':['max','min','mean','nunique'],\n",
    "      'weekofyear': ['mean','max','min','nunique'],\n",
    "      'weekend': ['sum', 'mean'],\n",
    "      'weekday':['sum','mean'],\n",
    "      'hour': ['mean','max','min','nunique'], \n",
    "      'purchase_day':['nunique','max','min','mean'],\n",
    "      'pur_date':['max','min'],\n",
    "      'price' :['sum','mean','max','min','var'],\n",
    "      'duration' : ['mean','min','max','var','skew'],\n",
    "      'amount_month_ratio':['mean','min','max','var','skew'],\n",
    "\n",
    "    }\n",
    "    featured_data=data.groupby(['card_id']).agg(agg_func)\n",
    "    col_list=[]\n",
    "    for col in featured_data.columns:\n",
    "        col_str='_'.join(col)\n",
    "        col_str=str_data + col_str\n",
    "        ren_name=col_str.split(\",\")\n",
    "        col_list.extend(ren_name)\n",
    "        \n",
    "    col_list.insert(0,'card_id')\n",
    "    featured_data.reset_index(inplace=True)\n",
    "    return featured_data,col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def additional_feature(data,str):\n",
    "  data[str +'_purchase_date_max'] = pd.to_datetime(data[str + '_pur_date_max'])\n",
    "  data[str + '_purchase_date_min'] = pd.to_datetime(data[str + '_pur_date_min'])\n",
    "  data[str + '_purchase_date_diff'] = (data[str + '_purchase_date_max'] - data[str + '_purchase_date_min']).dt.days\n",
    "  data[str + '_purchase_date_average'] = data[str + '_purchase_date_diff']/data[str + '_card_id_size']\n",
    "  data[str + '_purchase_date_uptonow'] = (datetime.datetime.today() - data[str + '_purchase_date_max']).dt.days\n",
    "  data[str + '_purchase_date_uptomin'] = (datetime.datetime.today() - data[str + '_purchase_date_min']).dt.days\n",
    "  data[str + '_first_buy'] = (data[str + '_purchase_date_min'] - data['first_active_month']).dt.days\n",
    "  data[str + '_last_buy'] = (data[str + '_purchase_date_max'] - data['first_active_month']).dt.days\n",
    "  \n",
    "  if (str=='hist'):\n",
    "    for feature in [str + '_purchase_date_max', str + '_purchase_date_min']:\n",
    "      data[feature] = data[feature].astype(np.int64) * 1e-9\n",
    "  \n",
    "  if (str=='new'):\n",
    "    for feature in ['new_purchase_date_max','new_purchase_date_min']:\n",
    "      data[feature] = pd.DatetimeIndex(data[feature]).astype(np.int64) * 1e-9\n",
    "  \n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_feature(data):\n",
    "  data['card_id_total'] = data['new_card_id_size'] + data['hist_card_id_size']\n",
    "  data['card_id_cnt_total'] = data['new_card_id_count'] + data['hist_card_id_count']\n",
    "  data['card_id_cnt_ratio'] = data['new_card_id_count'] / data['hist_card_id_count']\n",
    "  data['purchase_amount_total'] = data['new_purchase_amount_sum'] + data['hist_purchase_amount_sum']\n",
    "  data['purchase_amount_mean'] = data['new_purchase_amount_mean'] + data['hist_purchase_amount_mean']\n",
    "  data['purchase_amount_max'] = data['new_purchase_amount_max'] + data['hist_purchase_amount_max']\n",
    "  data['purchase_amount_min'] = data['new_purchase_amount_min']+ data['hist_purchase_amount_min']\n",
    "  data['purchase_amount_ratio'] = data['new_purchase_amount_sum'] / data['hist_purchase_amount_sum']\n",
    "  data['month_diff_mean'] = data['new_months_diff_mean'] + data['hist_months_diff_mean']\n",
    "  data['month_diff_ratio'] = data['new_months_diff_mean'] / data['hist_months_diff_mean']\n",
    "  data['month_lag_mean'] = data['new_month_lag_mean'] + data['hist_month_lag_mean']\n",
    "  data['month_lag_max'] = data['new_month_lag_max'] + data['hist_month_lag_max']\n",
    "  data['month_lag_min'] = data['new_month_lag_min']+ data['hist_month_lag_min']\n",
    "  data['category_1_mean'] = data['new_category_1_mean'] + data['hist_category_1_mean']\n",
    "  data['installments_total'] = data['new_installments_sum'] + data['hist_installments_sum']\n",
    "  data['installments_mean'] = data['new_installments_mean'] + data['hist_installments_mean']\n",
    "  data['installments_max'] = data['new_installments_max'] + data['hist_installments_max']\n",
    "  data['installments_ratio'] = data['new_installments_sum'] / data['hist_installments_sum']\n",
    "  data['price_total'] = data['purchase_amount_total'] / data['installments_total']\n",
    "  data['price_mean'] = data['purchase_amount_mean'] / data['installments_mean']\n",
    "  data['price_max'] = data['purchase_amount_max'] / data['installments_max']\n",
    "  data['duration_mean'] = data['new_duration_mean'] + data['hist_duration_mean']\n",
    "  data['duration_min'] = data['new_duration_min'] + data['hist_duration_min']\n",
    "  data['duration_max'] = data['new_duration_max'] + data['hist_duration_max']\n",
    "  data['amount_month_ratio_mean']= data['new_amount_month_ratio_mean'] + data['hist_amount_month_ratio_mean']\n",
    "  data['amount_month_ratio_min'] = data['new_amount_month_ratio_min'] + data['hist_amount_month_ratio_min']\n",
    "  data['amount_month_ratio_max']= data['new_amount_month_ratio_max'] + data['hist_amount_month_ratio_max']\n",
    "  data['new_CLV'] = data['new_card_id_count'] * data['new_purchase_amount_sum'] / data['new_months_diff_mean']\n",
    "  data['hist_CLV'] = data['hist_card_id_count'] * data['hist_purchase_amount_sum'] / data['hist_months_diff_mean']\n",
    "  data['CLV_ratio'] = data['new_CLV'] / data['hist_CLV']\n",
    "\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "predicts the loyalty score for a new customer\n",
    "\"\"\"\n",
    "def loyalty_score_prediction_new_1(param):\n",
    "    all_features=new_cust_feature(param)\n",
    "    predictions_1 = np.zeros(len(all_features))\n",
    "    \n",
    "    lgbm_1 = joblib.load('../input/finalmodel/lgb_model-1.pkl')\n",
    "    predictions_1 += lgbm_1.predict(all_features) / 5\n",
    "    \n",
    "    lgbm_2 = joblib.load('../input/finalmodel/lgb_model-2.pkl')\n",
    "    predictions_2 = np.zeros(len(all_features))\n",
    "    predictions_2 += lgbm_2.predict(all_features) / (5*2)\n",
    "    \n",
    "    final_model = joblib.load('../input/finalmodel/lgb_model-3.pkl')\n",
    "    predictions_3 = np.zeros(len(all_features))\n",
    "    test_stack = np.vstack([predictions_1, predictions_2]).transpose()\n",
    "    predictions_3 += final_model.predict(test_stack) / 5\n",
    "    \n",
    "    return predictions_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "predicts the loyalty scoreas well as RMSE  for a new customer\n",
    "\"\"\"\n",
    "def loyalty_score_prediction_new_2(param,target):\n",
    "    all_features=new_cust_feature(param)\n",
    "    #oof = np.zeros(len(train))\n",
    "    predictions_1 = np.zeros(len(all_features))\n",
    "    \n",
    "    lgbm_1 = joblib.load('../input/finalmodel/lgb_model-1.pkl')\n",
    "    predictions_1 += lgbm_1.predict(all_features) / 5\n",
    "    \n",
    "    lgbm_2 = joblib.load('../input/finalmodel/lgb_model-2.pkl')\n",
    "    predictions_2 = np.zeros(len(all_features))\n",
    "    predictions_2 += lgbm_2.predict(all_features) / (5*2)\n",
    "    \n",
    "    final_model = joblib.load('../input/finalmodel/lgb_model-3.pkl')\n",
    "    predictions_3 = np.zeros(len(all_features))\n",
    "    test_stack = np.vstack([predictions_1, predictions_2]).transpose()\n",
    "    predictions_3 += final_model.predict(test_stack) / 5\n",
    "    rmse=root_mean_squared_error(target,predictions_3)\n",
    "    return predictions_3,rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "calculates the features for a new customer\n",
    "\"\"\"\n",
    "\n",
    "def new_cust_feature(param):\n",
    "    train = [{'first_active_month': param['first_active_month'],'card_id':param['card_id'], 'feature_1':param['feature_1'],'feature_2':param['feature_2'],'feature_3':param['feature_3']}]\n",
    "    hist=[{'authorized_flag':param['hist_authorized_flag'],'card_id':param['card_id'],'city_id':param['hist_city_id'],'category_1':param['hist_category_1'],'installments':param['hist_installments'],'category_3':param['hist_category_3'],'merchant_category_id':param['hist_merchant_category_id'],'merchant_id':param['hist_merchant_id'],'month_lag':param['hist_month_lag'],'purchase_amount':param['hist_purchase_amount'],'purchase_date':param['hist_purchase_date'],'category_2':param['hist_category_2'],'state_id':param['hist_state_id'],'subsector_id':param['hist_subsector_id']}]\n",
    "    new=[{'authorized_flag':param['new_authorized_flag'],'card_id':param['card_id'],'city_id':param['new_city_id'],'category_1':param['new_category_1'],'installments':param['new_installments'],'category_3':param['new_category_3'],'merchant_category_id':param['new_merchant_category_id'],'merchant_id':param['new_merchant_id'],'month_lag':param['new_month_lag'],'purchase_amount':param['new_purchase_amount'],'purchase_date':param['new_purchase_date'],'category_2':param['new_category_2'],'state_id':param['new_state_id'],'subsector_id':param['new_subsector_id']}]\n",
    "    train_csv = pd.DataFrame(train)\n",
    "    historical_transactions=pd.DataFrame(hist)\n",
    "    new_merchant_transactions=pd.DataFrame(new)\n",
    "    \n",
    "    \n",
    "    order_label_1 = pd.read_pickle('../input/data-prod/feature_1')\n",
    "    order_label_2 = pd.read_pickle('../input/data-prod/feature_2')\n",
    "    order_label_3 = pd.read_pickle('../input/data-prod/feature_3')\n",
    "    \n",
    "    for features in ['feature_1','feature_2','feature_3']:\n",
    "        if(features=='feature_1'):\n",
    "            train_csv[features] = train_csv[features].map(order_label_1)\n",
    "        if(features=='feature_2'):\n",
    "            train_csv[features] = train_csv[features].map(order_label_2)\n",
    "        if(features=='feature_3'):\n",
    "            train_csv[features] = train_csv[features].map(order_label_3)\n",
    "    \n",
    "    train_csv['first_active_month']=pd.to_datetime(train_csv['first_active_month'],format='%Y-%m')\n",
    "    #print(df['first_active_month'])\n",
    "    train_csv['day'] = (datetime.date(2018, 2, 1) - train_csv['first_active_month'].dt.date).dt.days\n",
    "    train_csv['quarter'] = train_csv['first_active_month'].dt.quarter\n",
    "    \n",
    "    for feature in ['feature_1','feature_2','feature_3']:\n",
    "        column=feature+'_day'\n",
    "        train_csv[column] = train_csv['day'] * train_csv[feature]\n",
    "        column=feature+'_day_ratio'\n",
    "        train_csv[column] = train_csv[feature] / train_csv['day']\n",
    "    \n",
    "    #history\n",
    "    historical_transactions['purchase_amount'] = historical_transactions['purchase_amount'].apply(lambda x: min(x, 0.8))\n",
    "\n",
    "    #new\n",
    "    new_merchant_transactions['purchase_amount'] = new_merchant_transactions['purchase_amount'].apply(lambda x: min(x, 0.8))\n",
    "    \n",
    "    #history\n",
    "    historical_transactions['authorized_flag'] = historical_transactions['authorized_flag'].map({'Y': 1, 'N': 0})\n",
    "    historical_transactions['category_1'] = historical_transactions['category_1'].map({'Y': 1, 'N': 0})\n",
    "    historical_transactions['category_3'] = historical_transactions['category_3'].map({'A': 1, 'B': 2, 'C': 3})\n",
    "\n",
    "    #new\n",
    "    new_merchant_transactions['authorized_flag'] = new_merchant_transactions['authorized_flag'].map({'Y': 1, 'N': 0})\n",
    "    new_merchant_transactions['category_1'] = new_merchant_transactions['category_1'].map({'Y': 1, 'N': 0})\n",
    "    new_merchant_transactions['category_3'] = new_merchant_transactions['category_3'].map({'A':0, 'B':1, 'C':2})\n",
    "    \n",
    "    #history\n",
    "    historical_transactions['pur_date'] = pd.DatetimeIndex(historical_transactions['purchase_date']).date\n",
    "    historical_transactions['pur_date'] = pd.DatetimeIndex(historical_transactions['pur_date']).astype(np.int64) * 1e-9\n",
    "\n",
    "    #new\n",
    "    new_merchant_transactions['pur_date'] = pd.DatetimeIndex(new_merchant_transactions['purchase_date']).date\n",
    "    new_merchant_transactions['pur_date'] = pd.DatetimeIndex(new_merchant_transactions['pur_date']).astype(np.int64) * 1e-9\n",
    "\n",
    "    #history\n",
    "    historical_transactions['purchase_date']=pd.to_datetime(historical_transactions['purchase_date'],format='%Y-%m')\n",
    "\n",
    "    #new\n",
    "    new_merchant_transactions['purchase_date']=pd.to_datetime(new_merchant_transactions['purchase_date'],format='%Y-%m')\n",
    "    \n",
    "    \n",
    "    historical_transactions = date_features(historical_transactions)\n",
    "    new_merchant_transactions = date_features(new_merchant_transactions)\n",
    "    \n",
    "    #other features:\n",
    "    historical_transactions['duration'] = historical_transactions['purchase_amount'] * historical_transactions['months_diff']\n",
    "    historical_transactions['amount_month_ratio'] = historical_transactions['purchase_amount'] / historical_transactions['months_diff']\n",
    "    historical_transactions['price'] = historical_transactions['purchase_amount'] / historical_transactions['installments']\n",
    "\n",
    "    new_merchant_transactions['duration'] = new_merchant_transactions['purchase_amount'] * new_merchant_transactions['months_diff']\n",
    "    new_merchant_transactions['amount_month_ratio'] = new_merchant_transactions['purchase_amount'] / new_merchant_transactions['months_diff']\n",
    "    new_merchant_transactions['price'] = new_merchant_transactions['purchase_amount'] / new_merchant_transactions['installments']\n",
    "    \n",
    "    for i in ['category_2','category_3']:\n",
    "        historical_transactions[i + '_mean']=historical_transactions['purchase_amount'].groupby(historical_transactions[i]).agg('mean')\n",
    "        historical_transactions[i + '_min']=historical_transactions['purchase_amount'].groupby(historical_transactions[i]).agg('min')\n",
    "        historical_transactions[i + '_max']=historical_transactions['purchase_amount'].groupby(historical_transactions[i]).agg('max')\n",
    "        historical_transactions[i + '_sum']=historical_transactions['purchase_amount'].groupby(historical_transactions[i]).agg('sum')\n",
    "        historical_transactions[i + '_var']=historical_transactions['purchase_amount'].groupby(historical_transactions[i]).agg('var')\n",
    "\n",
    "        new_merchant_transactions[i + '_mean']=new_merchant_transactions['purchase_amount'].groupby(new_merchant_transactions[i]).agg('mean')\n",
    "        new_merchant_transactions[i + '_min']=new_merchant_transactions['purchase_amount'].groupby(new_merchant_transactions[i]).agg('min')\n",
    "        new_merchant_transactions[i + '_max']=new_merchant_transactions['purchase_amount'].groupby(new_merchant_transactions[i]).agg('max')\n",
    "        new_merchant_transactions[i + '_sum']=new_merchant_transactions['purchase_amount'].groupby(new_merchant_transactions[i]).agg('sum')\n",
    "        new_merchant_transactions[i + '_var']=new_merchant_transactions['purchase_amount'].groupby(new_merchant_transactions[i]).agg('var')\n",
    "    \n",
    "    hist_trans,col_list=aggregate_func(historical_transactions,'hist_')\n",
    "    hist_trans.columns=col_list\n",
    "    \n",
    "    new_trans,col_list=aggregate_func(new_merchant_transactions,'new_')\n",
    "    new_trans.columns=col_list\n",
    "    \n",
    "    train_data=pd.merge(train_csv,hist_trans,on='card_id',how='left')\n",
    "    train_data=pd.merge(train_data,new_trans,on='card_id',how='left')\n",
    "    \n",
    "    train_data=additional_feature(train_data,'hist')\n",
    "    train_data=additional_feature(train_data,'new')\n",
    "    \n",
    "    train=combined_feature(train_data)\n",
    "    \n",
    "    with open(\"../input/feature/feature.txt\", \"rb\") as fp:\n",
    "        features = pickle.load(fp)\n",
    "    \n",
    "    feature = [c for c in train.columns if c not in ['first_active_month', 'target', 'card_id', 'outliers',\n",
    "                  'hist_purchase_date_max', 'hist_purchase_date_min', 'hist_card_id_size',\n",
    "                  'new_purchase_date_max', 'new_purchase_date_min', 'new_card_id_size']] \n",
    "    return train[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------\n",
      "loyalty score: [0.02744678]\n",
      "Total execution time: 0:00:00.433255\n",
      "--------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------------\n",
      "loyalty score is: [0.02744678]\n",
      "RMSE is: 0.11500922256225433\n",
      "Total execution time: 0:00:00.453006\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "existing_cust=False\n",
    "\n",
    "if (existing_cust):\n",
    "    param={\n",
    "    'first_active_month':'2017-08-01',\n",
    "    'card_id':'C_ID_186d6a6901',\n",
    "    'feature_1':4,\n",
    "    'feature_2':3,\n",
    "    'feature_3':0\n",
    "    }\n",
    "    start_time = datetime.datetime.now()\n",
    "    score=loyalty_score_prediction_1(param)\n",
    "    end_time = datetime.datetime.now()\n",
    "    print(\"--------------------------------------------------------------------------------------\")\n",
    "    print('loyalty score:',score)\n",
    "    print(\"Total execution time:\",(end_time-start_time))\n",
    "    print(\"--------------------------------------------------------------------------------------\")\n",
    "\n",
    "    start_time = datetime.datetime.now()\n",
    "    score,rmse=loyalty_score_prediction_2(param,-0.06540639)\n",
    "    end_time = datetime.datetime.now()\n",
    "    print(\"--------------------------------------------------------------------------------------\")\n",
    "    print('loyalty score:',score)\n",
    "    print(\"RMSE:\",rmse)\n",
    "    print(\"Total execution time:\",(end_time-start_time))\n",
    "    print(\"--------------------------------------------------------------------------------------\")\n",
    "        \n",
    "else:\n",
    "    param={\n",
    "        'first_active_month':'2017-09',\n",
    "        'card_id':'C_ID_186d6a6901',\n",
    "        'feature_1':4,\n",
    "        'feature_2':3,\n",
    "        'feature_3':0,\n",
    "        'hist_authorized_flag':'Y',\n",
    "        'hist_city_id':17,\n",
    "        'hist_category_1':'N',\n",
    "        'hist_installments':1,\n",
    "        'hist_category_3':'B',\n",
    "        'hist_merchant_category_id':195,\n",
    "        'hist_merchant_id':'M_ID_309752ddea',\n",
    "        'hist_month_lag':-1,\n",
    "        'hist_purchase_amount':-0.716855,\n",
    "        'hist_purchase_date':'2018-01-31 16:23:49',\n",
    "        'hist_category_2':4.0,\n",
    "        'hist_state_id':22,\n",
    "        'hist_subsector_id':34,\n",
    "        'new_authorized_flag':'Y',\n",
    "        'new_city_id':17,\n",
    "        'new_category_1':'N',\n",
    "        'new_installments':1,\n",
    "        'new_category_3':'B',\n",
    "        'new_merchant_category_id':195,\n",
    "        'new_merchant_id':'M_ID_309752ddea',\n",
    "        'new_month_lag':-1,\n",
    "        'new_purchase_amount':-0.716855,\n",
    "        'new_purchase_date':'2018-01-31 16:23:49',\n",
    "        'new_category_2':4.0,\n",
    "        'new_state_id':22,\n",
    "        'new_subsector_id':34    \n",
    "    }\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    score=loyalty_score_prediction_new_1(param)\n",
    "    end_time = datetime.datetime.now()\n",
    "    print(\"--------------------------------------------------------------------------------------\")\n",
    "    print('loyalty score:',score)\n",
    "    print(\"Total execution time:\",(end_time-start_time))\n",
    "    print(\"--------------------------------------------------------------------------------------\")\n",
    "    start_time = datetime.datetime.now()\n",
    "    score,rmse=loyalty_score_prediction_new_2(param,0.142456)\n",
    "    end_time = datetime.datetime.now()\n",
    "    print(\"--------------------------------------------------------------------------------------\")\n",
    "    print(\"loyalty score is:\",score)\n",
    "    print(\"RMSE is:\",rmse)\n",
    "    print(\"Total execution time:\",(end_time-start_time))\n",
    "    print(\"--------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
